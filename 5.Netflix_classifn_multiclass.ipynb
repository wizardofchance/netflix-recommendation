{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.Netflix_classifn_multiclassipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"099kL0VDL-Mr","colab_type":"code","outputId":"ac14582d-6559-4781-963b-875408e16874","executionInfo":{"status":"ok","timestamp":1546486275744,"user_tz":-330,"elapsed":35417,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"Dasheb6nMC81","colab_type":"code","outputId":"c006cf30-b2b9-4d07-ac38-707c69e85562","executionInfo":{"status":"ok","timestamp":1546486309852,"user_tz":-330,"elapsed":37614,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x57e04000 @  0x7fb3ffa662a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"],"name":"stdout"}]},{"metadata":{"id":"H5ROnnrFMNG5","colab_type":"code","colab":{}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BW4CgKeDMPQf","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from collections import Counter\n","\n","import torch\n","import torch.nn as nn\n","\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mc1nNeqEMRfA","colab_type":"code","outputId":"233794cb-4c28-448f-855b-774b5313ec38","executionInfo":{"status":"ok","timestamp":1546486309867,"user_tz":-330,"elapsed":35828,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"SM6ku5eHMThA","colab_type":"code","colab":{}},"cell_type":"code","source":["path='gdrive/My Drive/netflix_colab/data/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WA7bGwEH0i6T","colab_type":"text"},"cell_type":"markdown","source":["# CREATING PYTORCH DATA CLASS:"]},{"metadata":{"id":"VBIMZ5RyMpv6","colab_type":"code","colab":{}},"cell_type":"code","source":["class Recommender_Data_Classifn(Dataset):\n","\n","    def __init__(self, path, csv_file_name):\n","        \n","        df = pd.read_csv(path + csv_file_name, index_col = 0)\n","        x  = df.iloc[:, :-1].values\n","        y  = df.iloc[:, -1].values - 1   #-1 becoz C.E.LOSS infers n_classes from dimensionality of y_pred as range(y_pred.shape[0])\n","                                         # ie: If 5 classes present then labels should belong to interval (0, 4)\n","        self.len = df.shape[0]\n","        \n","        self.x_data = torch.from_numpy(x).type(torch.LongTensor)\n","        self.y_data = torch.from_numpy(y).type(torch.LongTensor)\n","\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    def __len__(self):\n","        return self.len"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3SabBynqMpzA","colab_type":"code","colab":{}},"cell_type":"code","source":["train_dataset = Recommender_Data_Classifn(path, 'df_final_trainset.csv')\n","test_dataset  = Recommender_Data_Classifn(path, 'df_final_testset.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pxq3ptoUMvwH","colab_type":"code","outputId":"d8b462a4-33a8-4a9d-dbe2-b05bdfe5fade","executionInfo":{"status":"ok","timestamp":1546486399521,"user_tz":-330,"elapsed":843,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"cell_type":"code","source":["train_dataset.x_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    0,     0],\n","        [    1,     1],\n","        [    2,     2],\n","        ...,\n","        [ 3652,  8903],\n","        [   56, 10623],\n","        [  263, 39396]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"DljXaxu7Myuv","colab_type":"code","outputId":"6de57ffb-93ff-4a78-c98a-4e0e292a3351","executionInfo":{"status":"ok","timestamp":1546486402598,"user_tz":-330,"elapsed":815,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["train_dataset.y_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 4, 2,  ..., 0, 3, 4])"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"wmctfwd20u4e","colab_type":"text"},"cell_type":"markdown","source":["# TRAIN-EVALUATION FUNCTION:"]},{"metadata":{"id":"KCq3q6sQtBdP","colab_type":"code","colab":{}},"cell_type":"code","source":["def fn_train_eval(model, train_set, test_set, batch_size, criterion, optimizer, n_epochs):\n","    \n","    # INNER FNS---------------------------------------------\n","    def retrn_scalar_y_pred(y_pred):\n","        _, y_pred_scalar = torch.max(y_pred, dim = 1) # idxs of max vals of each y_pred\n","        return y_pred_scalar\n","\n","    def retrn_n_matches(y_pred_scalar, target):\n","        n_matches = (y_pred_scalar == target).sum().item()\n","        return n_matches\n","    \n","    # TRAIN & TEST SET BATCH GENERATORS----------------------\n","    train_iterator = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n","    test_iterator  = DataLoader(dataset=test_set,  batch_size=batch_size, shuffle=True, num_workers=2)\n","    \n","    # EPOCH LOOPS--------------------------------------------\n","    listO_models = []\n","    listO_train_losses, listO_test_losses = [], []\n","    listO_train_acc, listO_test_acc = [], []\n","    c1, c2 = 'print', 'print'\n","    for epoch in range(n_epochs):\n","        model.to(device)\n","        \n","        # TRAIN_LOOPS-----------------------------------------\n","        n_matches_train = 0\n","        iter_loss_train = 0.0\n","        model.train()\n","        for batch_idx, batch in enumerate(train_iterator):\n","            \n","            movies  = Variable(batch[0][:, 0]).to(device)\n","            users   = Variable(batch[0][:, 1]).to(device)\n","            ratings = Variable(batch[1]).to(device)                               # make data diffrentiable\n","            \n","            optimizer.zero_grad()                                                 # Init\n","            y_pred = model(users, movies)                                         # Predict\n","            loss_train = criterion(y_pred, ratings)                               # Calculate loss\n","            iter_loss_train += loss_train.data.item()                             # Accumulate the loss\n","            loss_train.backward()                                                 # Backprop\n","            optimizer.step()                                                      # Update weights\n","            \n","            if c1 == 'print':\n","                print('TRAINING >>>>')                                            # confirmation!!\n","                c1 = 'no_print' \n","            \n","            y_pred_scalar = retrn_scalar_y_pred(y_pred)\n","            n_matches_train += retrn_n_matches(y_pred_scalar, ratings)\n","       \n","        # COLLECT TRAIN ACCURACIES & LOSSES--------------------    \n","        train_acc = n_matches_train/len(train_set) \n","        listO_train_acc.append(train_acc)\n","        train_loss = iter_loss_train/(batch_idx+1)\n","        listO_train_losses.append(train_loss)\n","        \n","        # COLLECT MODELS---------------------------------------\n","        listO_models.append(model)\n","        \n","        # EVAL_LOOPS-------------------------------------------\n","        n_matches_test = 0\n","        iter_loss_test = 0.0\n","        model.eval()\n","        with torch.no_grad():  \n","            for batch_idx, batch in enumerate(test_iterator):\n","                \n","                movies  = Variable(batch[0][:, 0]).to(device)\n","                users   = Variable(batch[0][:, 1]).to(device)\n","                ratings = Variable(batch[1]).to(device)  \n","                \n","                y_pred = model(users, movies)                         # Predict\n","                loss_test = criterion(y_pred, ratings)                # Calculate loss\n","                iter_loss_test += loss_test.data.item() \n","                \n","                if c2 == 'print':\n","                    print('EVALUATING >>>>')                          # confirmation!!\n","                    c2 = 'no_print' \n","                \n","                y_pred_scalar = retrn_scalar_y_pred(y_pred)\n","                n_matches_test += retrn_n_matches(y_pred_scalar, ratings)\n","        \n","        # COLLECT TEST ACCURACIES & LOSSES---------------------\n","        test_acc = n_matches_test/len(test_set)\n","        listO_test_acc.append(test_acc)\n","        test_loss = iter_loss_test/(batch_idx+1)\n","        listO_test_losses.append(test_loss)\n","\n","        # DISPLAY-----------------------------------------------\n","        params = [epoch+1, loss_train, loss_test, train_acc, test_acc]\n","        print('Epoch: {:03}  train_loss: {:.3f}  |  test_loss: {:.3f}  |  train_acc: {:.4f}  |  test_acc: {:.4f}'.format(*params))\n","        \n","    print()\n","    print('RETURNED: listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models')\n","    print()\n","    return listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0ZyZlx0b0qOJ","colab_type":"text"},"cell_type":"markdown","source":["# MODEL_1"]},{"metadata":{"id":"sJCY2l_uM8Rd","colab_type":"code","colab":{}},"cell_type":"code","source":["class Recommender_Classify_1(torch.nn.Module):\n","    \n","    def __init__(self, n_users, n_items, embedding_dim, dropout1, hidden_dim, dropout2, n_classes):\n","        super().__init__()\n","        \n","\t     # create user & item embeddings of same size:\n","        self.user_embeddings = nn.Embedding(n_users, embedding_dim, sparse=False)\n","        self.item_embeddings = nn.Embedding(n_items, embedding_dim, sparse=False)\n","        \n","        self.weights1 = nn.Linear(embedding_dim*2, hidden_dim)\n","        self.weights2 = nn.Linear(hidden_dim, n_classes)\n","        \n","        self.batch_norm1 = nn.BatchNorm1d(embedding_dim*2)\n","        self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n","        \n","        self.dropout1 = nn.Dropout2d(p=dropout1)\n","        self.dropout2 = nn.Dropout2d(p=dropout2)\n","        \n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim = 1)\n","        \n","    def forward(self, user, item):\n","        \n","    \t# CREATING USER LATENT VARIABLES\n","        \n","        # embedding\n","        user_vec = self.user_embeddings(user)\n","        item_vec = self.item_embeddings(item)\n","        \n","        # representation of iput(concat user & item vectors):\n","        input_vec = torch.cat((user_vec, item_vec), dim = 1)\n","                              \n","        # layer 1\n","        hidden = self.batch_norm1(input_vec) \n","        hidden = self.dropout1(hidden) \n","        hidden = self.weights1(hidden) \n","        hidden = self.relu(hidden)\n","        # layers 2 \n","        hidden = self.batch_norm2(hidden) \n","        hidden = self.dropout2(hidden) \n","        hidden = self.weights2(hidden) \n","        \n","        y_pred     = self.softmax(hidden)\n","        return y_pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M69LNPxSs6Mi","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 1:"]},{"metadata":{"id":"tUzSy72btNLU","colab_type":"code","outputId":"d19f5be6-2007-408a-de4a-8537486869d7","executionInfo":{"status":"ok","timestamp":1546489089530,"user_tz":-330,"elapsed":1903962,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"cell_type":"code","source":["n_users, n_items, embedding_dim, hidden_dim, n_classes = 50000, 5000, 50, 50, 5\n","dropout1, dropout2 = 0.5, 0.25\n","\n","model = Recommender_Classify_1(n_users, n_items, embedding_dim, dropout1, hidden_dim, dropout2, n_classes)\n","\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_set = train_dataset\n","test_set = test_dataset\n","batch_size = 1000                                                  \n","n_epochs = 30\n","\n","%time listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models = fn_train_eval(model, train_set, test_set, batch_size, criterion, optimizer, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>>>\n","EVALUATING >>>>\n","Epoch: 001  train_loss: 1.504  |  test_loss: 1.506  |  train_acc: 0.3562  |  test_acc: 0.3903\n","Epoch: 002  train_loss: 1.490  |  test_loss: 1.478  |  train_acc: 0.3930  |  test_acc: 0.4215\n","Epoch: 003  train_loss: 1.442  |  test_loss: 1.449  |  train_acc: 0.4160  |  test_acc: 0.4361\n","Epoch: 004  train_loss: 1.444  |  test_loss: 1.446  |  train_acc: 0.4293  |  test_acc: 0.4433\n","Epoch: 005  train_loss: 1.450  |  test_loss: 1.407  |  train_acc: 0.4381  |  test_acc: 0.4486\n","Epoch: 006  train_loss: 1.410  |  test_loss: 1.453  |  train_acc: 0.4453  |  test_acc: 0.4517\n","Epoch: 007  train_loss: 1.414  |  test_loss: 1.417  |  train_acc: 0.4504  |  test_acc: 0.4543\n","Epoch: 008  train_loss: 1.459  |  test_loss: 1.405  |  train_acc: 0.4548  |  test_acc: 0.4561\n","Epoch: 009  train_loss: 1.450  |  test_loss: 1.435  |  train_acc: 0.4585  |  test_acc: 0.4570\n","Epoch: 010  train_loss: 1.427  |  test_loss: 1.462  |  train_acc: 0.4613  |  test_acc: 0.4586\n","Epoch: 011  train_loss: 1.437  |  test_loss: 1.439  |  train_acc: 0.4640  |  test_acc: 0.4590\n","Epoch: 012  train_loss: 1.419  |  test_loss: 1.425  |  train_acc: 0.4662  |  test_acc: 0.4601\n","Epoch: 013  train_loss: 1.392  |  test_loss: 1.458  |  train_acc: 0.4683  |  test_acc: 0.4600\n","Epoch: 014  train_loss: 1.445  |  test_loss: 1.394  |  train_acc: 0.4701  |  test_acc: 0.4609\n","Epoch: 015  train_loss: 1.360  |  test_loss: 1.443  |  train_acc: 0.4720  |  test_acc: 0.4614\n","Epoch: 016  train_loss: 1.422  |  test_loss: 1.397  |  train_acc: 0.4736  |  test_acc: 0.4615\n","Epoch: 017  train_loss: 1.423  |  test_loss: 1.404  |  train_acc: 0.4748  |  test_acc: 0.4619\n","Epoch: 018  train_loss: 1.430  |  test_loss: 1.378  |  train_acc: 0.4763  |  test_acc: 0.4622\n","Epoch: 019  train_loss: 1.411  |  test_loss: 1.448  |  train_acc: 0.4772  |  test_acc: 0.4621\n","Epoch: 020  train_loss: 1.413  |  test_loss: 1.433  |  train_acc: 0.4784  |  test_acc: 0.4622\n","Epoch: 021  train_loss: 1.426  |  test_loss: 1.414  |  train_acc: 0.4793  |  test_acc: 0.4626\n","Epoch: 022  train_loss: 1.390  |  test_loss: 1.423  |  train_acc: 0.4803  |  test_acc: 0.4626\n","Epoch: 023  train_loss: 1.365  |  test_loss: 1.422  |  train_acc: 0.4814  |  test_acc: 0.4624\n","Epoch: 024  train_loss: 1.385  |  test_loss: 1.417  |  train_acc: 0.4819  |  test_acc: 0.4630\n","Epoch: 025  train_loss: 1.429  |  test_loss: 1.428  |  train_acc: 0.4826  |  test_acc: 0.4630\n","Epoch: 026  train_loss: 1.384  |  test_loss: 1.405  |  train_acc: 0.4836  |  test_acc: 0.4628\n","Epoch: 027  train_loss: 1.379  |  test_loss: 1.423  |  train_acc: 0.4842  |  test_acc: 0.4625\n","Epoch: 028  train_loss: 1.405  |  test_loss: 1.426  |  train_acc: 0.4849  |  test_acc: 0.4628\n","Epoch: 029  train_loss: 1.367  |  test_loss: 1.405  |  train_acc: 0.4857  |  test_acc: 0.4627\n","Epoch: 030  train_loss: 1.426  |  test_loss: 1.432  |  train_acc: 0.4861  |  test_acc: 0.4631\n","\n","RETURNED: listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models\n","\n","CPU times: user 12min 32s, sys: 3min 19s, total: 15min 52s\n","Wall time: 31min 43s\n"],"name":"stdout"}]},{"metadata":{"id":"nphh-6SxsMLM","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 2:"]},{"metadata":{"id":"dwxiRFZjto41","colab_type":"code","outputId":"3b2f9db8-ea70-44e2-a4d8-d46f2f0c1a16","executionInfo":{"status":"ok","timestamp":1546504318881,"user_tz":-330,"elapsed":1631935,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"cell_type":"code","source":["n_users, n_items, embedding_dim, hidden_dim, n_classes = 50000, 5000, 50, 50, 5\n","dropout1, dropout2 = 0, 0\n","\n","model = Recommender_Classify_1(n_users, n_items, embedding_dim, dropout1, hidden_dim, dropout2, n_classes)\n","\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_set = train_dataset\n","test_set = test_dataset\n","batch_size = 1000                                                  \n","n_epochs = 30\n","\n","%time listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models = fn_train_eval(model, train_set, test_set, batch_size, criterion, optimizer, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>>>\n","EVALUATING >>>>\n","Epoch: 001  train_loss: 1.445  |  test_loss: 1.423  |  train_acc: 0.3849  |  test_acc: 0.4170\n","Epoch: 002  train_loss: 1.437  |  test_loss: 1.442  |  train_acc: 0.4414  |  test_acc: 0.4429\n","Epoch: 003  train_loss: 1.434  |  test_loss: 1.412  |  train_acc: 0.4645  |  test_acc: 0.4501\n","Epoch: 004  train_loss: 1.426  |  test_loss: 1.426  |  train_acc: 0.4756  |  test_acc: 0.4530\n","Epoch: 005  train_loss: 1.430  |  test_loss: 1.455  |  train_acc: 0.4836  |  test_acc: 0.4542\n","Epoch: 006  train_loss: 1.419  |  test_loss: 1.461  |  train_acc: 0.4893  |  test_acc: 0.4543\n","Epoch: 007  train_loss: 1.412  |  test_loss: 1.450  |  train_acc: 0.4947  |  test_acc: 0.4542\n","Epoch: 008  train_loss: 1.381  |  test_loss: 1.427  |  train_acc: 0.4996  |  test_acc: 0.4541\n","Epoch: 009  train_loss: 1.393  |  test_loss: 1.426  |  train_acc: 0.5042  |  test_acc: 0.4539\n","Epoch: 010  train_loss: 1.371  |  test_loss: 1.446  |  train_acc: 0.5087  |  test_acc: 0.4535\n","Epoch: 011  train_loss: 1.368  |  test_loss: 1.463  |  train_acc: 0.5128  |  test_acc: 0.4534\n","Epoch: 012  train_loss: 1.371  |  test_loss: 1.427  |  train_acc: 0.5173  |  test_acc: 0.4527\n","Epoch: 013  train_loss: 1.398  |  test_loss: 1.401  |  train_acc: 0.5213  |  test_acc: 0.4518\n","Epoch: 014  train_loss: 1.380  |  test_loss: 1.433  |  train_acc: 0.5254  |  test_acc: 0.4519\n","Epoch: 015  train_loss: 1.389  |  test_loss: 1.459  |  train_acc: 0.5293  |  test_acc: 0.4512\n","Epoch: 016  train_loss: 1.353  |  test_loss: 1.474  |  train_acc: 0.5330  |  test_acc: 0.4507\n","Epoch: 017  train_loss: 1.377  |  test_loss: 1.415  |  train_acc: 0.5366  |  test_acc: 0.4507\n","Epoch: 018  train_loss: 1.343  |  test_loss: 1.466  |  train_acc: 0.5401  |  test_acc: 0.4500\n","Epoch: 019  train_loss: 1.343  |  test_loss: 1.497  |  train_acc: 0.5431  |  test_acc: 0.4499\n","Epoch: 020  train_loss: 1.350  |  test_loss: 1.427  |  train_acc: 0.5460  |  test_acc: 0.4496\n","Epoch: 021  train_loss: 1.404  |  test_loss: 1.409  |  train_acc: 0.5487  |  test_acc: 0.4498\n","Epoch: 022  train_loss: 1.355  |  test_loss: 1.498  |  train_acc: 0.5514  |  test_acc: 0.4494\n","Epoch: 023  train_loss: 1.329  |  test_loss: 1.443  |  train_acc: 0.5536  |  test_acc: 0.4488\n","Epoch: 024  train_loss: 1.322  |  test_loss: 1.465  |  train_acc: 0.5561  |  test_acc: 0.4485\n","Epoch: 025  train_loss: 1.332  |  test_loss: 1.397  |  train_acc: 0.5582  |  test_acc: 0.4487\n","Epoch: 026  train_loss: 1.347  |  test_loss: 1.467  |  train_acc: 0.5601  |  test_acc: 0.4482\n","Epoch: 027  train_loss: 1.336  |  test_loss: 1.436  |  train_acc: 0.5619  |  test_acc: 0.4482\n","Epoch: 028  train_loss: 1.336  |  test_loss: 1.457  |  train_acc: 0.5636  |  test_acc: 0.4476\n","Epoch: 029  train_loss: 1.344  |  test_loss: 1.432  |  train_acc: 0.5651  |  test_acc: 0.4480\n","Epoch: 030  train_loss: 1.370  |  test_loss: 1.461  |  train_acc: 0.5666  |  test_acc: 0.4478\n","\n","RETURNED: listO_train_losses, listO_test_losses, listO_train_acc, listO_test_acc, listO_models\n","\n","CPU times: user 11min 7s, sys: 3min 11s, total: 14min 18s\n","Wall time: 27min 10s\n"],"name":"stdout"}]},{"metadata":{"id":"L7L7cwGdto8e","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"aj4dbOSctpAI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"G-YcT-p7rIHO","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"uwhieHH1rIKl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"PaMGX35CreE_","colab_type":"text"},"cell_type":"markdown","source":["# ROUGH WORK :"]},{"metadata":{"id":"NUpeGB1nroNN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"626wacIlrxhn","colab_type":"text"},"cell_type":"markdown","source":["### CROSS ENTROPY LOSS"]},{"metadata":{"id":"SYOzZdpzrIWX","colab_type":"code","outputId":"aeb7d5ba-cb23-404d-eb6f-6dbe25197421","executionInfo":{"status":"ok","timestamp":1546501574023,"user_tz":-330,"elapsed":884,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["torch.empty(3, dtype=torch.long).random_(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 4, 0])"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"UbbgYDe6tpVz","colab_type":"code","colab":{}},"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","input = torch.randn(3, 5, requires_grad=True)\n","target = torch.empty(3, dtype=torch.long).random_(5)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GimSTfW9tpZG","colab_type":"code","outputId":"71fd7286-8d4b-4ec7-e9b3-35243f380f8e","executionInfo":{"status":"ok","timestamp":1546501577110,"user_tz":-330,"elapsed":902,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["input"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.4187, -0.0201, -0.8396,  1.0466,  0.6363],\n","        [ 0.4213,  0.4998, -0.6429, -0.1832,  1.4841],\n","        [-0.2525, -1.7729,  0.9540,  2.0658,  1.0311]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"Z4bUW_QxtpdL","colab_type":"code","outputId":"141c651b-a60b-43ee-dc0c-072457c8d455","executionInfo":{"status":"ok","timestamp":1546501578478,"user_tz":-330,"elapsed":680,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["target"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 3, 4])"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"id":"uHg-3uDErPB7","colab_type":"code","outputId":"3fc35687-f0ab-45f4-cd13-d39d8452adec","executionInfo":{"status":"ok","timestamp":1546501579718,"user_tz":-330,"elapsed":557,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["output = loss(input, target)\n","output.backward()\n","output"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.1118, grad_fn=<NllLossBackward>)"]},"metadata":{"tags":[]},"execution_count":32}]},{"metadata":{"id":"0QzYF7vGrPOL","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rpv6rTZNrPR0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"buOPyRxqr4mv","colab_type":"text"},"cell_type":"markdown","source":["### CHECKING COMPATIBILITY  BATCH FORMAT, MODEL PREDICTION & LOSS FN:"]},{"metadata":{"id":"XajTTl8pNMJN","colab_type":"code","colab":{}},"cell_type":"code","source":["model#.to(device)\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","criterion = criterion#.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lvrLV48MNelk","colab_type":"code","colab":{}},"cell_type":"code","source":["train_iterator = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True, num_workers=2)\n","for batch_idx, batch in enumerate(train_iterator):\n","\n","        movies  = Variable(batch[0][:, 0])#.to(device)\n","        users   = Variable(batch[0][:, 1])#.to(device)\n","        ratings = Variable(batch[1])#.to(device)                               \n","\n","        optimizer.zero_grad()                                                 \n","        y_pred = model(users, movies) \n","        \n","        loss_train = criterion(y_pred, ratings)   \n","        if batch_idx == 0: break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kOt7_ArEN3qs","colab_type":"code","outputId":"9d616502-c48e-41a9-93e5-4b3ff0b279db","executionInfo":{"status":"ok","timestamp":1546451362104,"user_tz":-330,"elapsed":885,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["y_pred"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2418, 0.0957, 0.3182, 0.2439, 0.1004],\n","        [0.1615, 0.1615, 0.1833, 0.3323, 0.1615]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":69}]},{"metadata":{"id":"bm2_g6D8N51T","colab_type":"code","outputId":"7038e715-66f9-4364-a0a9-e7d6916874ca","executionInfo":{"status":"ok","timestamp":1546451366270,"user_tz":-330,"elapsed":870,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["ratings"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 0])"]},"metadata":{"tags":[]},"execution_count":70}]},{"metadata":{"id":"Acf35-Q-N87a","colab_type":"code","outputId":"8d4c0112-08db-433a-8233-a33964c69d14","executionInfo":{"status":"ok","timestamp":1546451369658,"user_tz":-330,"elapsed":868,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["loss_train "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.5727, grad_fn=<NllLossBackward>)"]},"metadata":{"tags":[]},"execution_count":71}]},{"metadata":{"id":"QVtGM8Z2sBiU","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"u1mzeefhrDOC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}