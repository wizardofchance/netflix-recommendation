{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_Netflix_MatrixFactorization_regressn_Model_2.ipynb","version":"0.3.2","provenance":[{"file_id":"1mssiwukX4nE7yXp9810GGrKwbyjJvPAh","timestamp":1546333171741},{"file_id":"1mhaU02olkO-y2UF1R7TWQ1qONThvKvDA","timestamp":1545731653291}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_nUu-wSpHTpu","colab_type":"code","outputId":"dfb8cf8e-8e22-445f-d1d3-1cbb0b3e2475","executionInfo":{"status":"ok","timestamp":1546359485334,"user_tz":-330,"elapsed":30686,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"92_csDx8xPbm","colab_type":"code","outputId":"88ef1acc-72d9-417a-b836-133be9db9190","executionInfo":{"status":"ok","timestamp":1546359528426,"user_tz":-330,"elapsed":36215,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x57b4a000 @  0x7f0d90dc02a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"],"name":"stdout"}]},{"metadata":{"id":"7DTAZ9bRxcge","colab_type":"code","colab":{}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UI1Rg1Tyxcok","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VY5NKfwZ14Q5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"lqV0LXNX14Zf","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"6eor0CeBX1sC","colab_type":"text"},"cell_type":"markdown","source":["# START:"]},{"metadata":{"colab_type":"code","id":"Z0yFJqhxo5vl","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","from collections import Counter\n","\n","import torch\n","import torch.nn as nn\n","\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FF8KtFUangJD","colab_type":"text"},"cell_type":"markdown","source":["### DEVICE:"]},{"metadata":{"colab_type":"code","id":"DvFCTRWcdRwv","outputId":"c3e5fd0a-9ad9-427a-a1d5-508fe82447ae","executionInfo":{"status":"ok","timestamp":1546359535844,"user_tz":-330,"elapsed":1286,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"orF1Xpfcni_t","colab_type":"text"},"cell_type":"markdown","source":["### PATH:"]},{"metadata":{"id":"-dIYIlQ9DPbA","colab_type":"code","colab":{}},"cell_type":"code","source":["path='gdrive/My Drive/netflix_colab/data/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8MkzbgoG10ET","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"G8rndNjE10RD","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"colab_type":"text","id":"Cqreq3MPpMat"},"cell_type":"markdown","source":["## FUNCTONS:"]},{"metadata":{"id":"T_GRKpbJzs9_","colab_type":"text"},"cell_type":"markdown","source":["### 1. FN FOR TRAINING & VALIDATION:"]},{"metadata":{"id":"m8B2BEBSnPdQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs):\n","    \n","  \n","    # INNER FUNCTIONS-----------------------------------------------\n","    \n","    def fn_train(model, iterator, optimizer, criterion):\n","\n","        epoch_loss = 0\n","        model.train()\n","        for batch in iterator:\n","            \n","            movies  = Variable(batch[0][:, 0]).to(device)\n","            users   = Variable(batch[0][:, 1]).to(device)\n","            ratings = Variable(batch[1]).to(device)\n","            \n","            optimizer.zero_grad()                   # INITIALIZE\n","            \n","            predictions = model(users, movies)      # PREDICT\n","            loss = criterion(predictions, ratings)  # COMPUTE LOSS\n","\n","            loss.backward()                         # BACK PROP\n","            optimizer.step()                        # GRADIENT DESCENT\n","\n","            epoch_loss += loss.item()\n","\n","        epoch_loss = epoch_loss/len(iterator)\n","\n","        return epoch_loss \n","\n","\n","    def fn_evaluate(model, iterator, criterion):\n","\n","        epoch_loss = 0\n","        model.eval()\n","        with torch.no_grad():\n","\n","            for batch in iterator:\n","            \n","                movies  = Variable(batch[0][:, 0]).to(device)\n","                users   = Variable(batch[0][:, 1]).to(device)\n","                ratings = Variable(batch[1]).to(device)\n","\n","\n","                predictions = model(users, movies)\n","                loss = criterion(predictions, ratings)\n","\n","                epoch_loss += loss.item()\n","\n","        epoch_loss = epoch_loss/len(iterator)\n","\n","        return epoch_loss \n","    \n","    \n","    # RUN--------------------------------------------------------------------\n","\n","    train_iterator = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    test_iterator  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","    listO_train_losses, listO_test_losses = [], []\n","    \n","    c1, c2 = 'print', 'print'\n","    for epoch in range(n_epochs):\n","\n","        train_loss = fn_train(model, train_iterator, optimizer, criterion)\n","        if c1 == 'print':\n","            print('TRAINING >>')\n","            c1 = 'no_print'\n","\n","        test_loss = fn_evaluate(model, test_iterator, criterion)\n","        if c2 == 'print':\n","            print('EVALUATING >>')\n","            c2 = 'no_print'\n","\n","        listO_train_losses.append(train_loss)\n","        listO_test_losses.append(test_loss)\n","        \n","        print_params = [epoch+1, train_loss, test_loss]\n","        print('Epoch: {:03}  |  Train Loss: {:.3f}  | test Loss: {:.3f}  |'.format(*print_params))\n","        \n","    print()\n","    print('RETURNED: listO_train_losses, listO_test_losses, model')\n","    \n","    return listO_train_losses, listO_test_losses, model "],"execution_count":0,"outputs":[]},{"metadata":{"id":"pCUDzvc-z7AP","colab_type":"text"},"cell_type":"markdown","source":["### 2. PLOTTING FN:"]},{"metadata":{"id":"5cCAxHWfYA_v","colab_type":"code","colab":{}},"cell_type":"code","source":["def retrn_model_plots(listO_train_losses, listO_test_losses):\n","    \n","    import pylab\n","    pylab.rcParams[\"figure.figsize\"] = (10, 5)\n","\n","    xs = list(range(1, len(listO_train_losses)+1))\n","    ys = listO_train_losses\n","    ys_v = listO_test_losses\n","\n","\n","    pylab.plot(xs, ys, '-', label = 'train')\n","    pylab.plot(xs, ys_v, '-', label = 'test')\n","\n","    pylab.legend()\n","    pylab.xlabel('EPOCHS')\n","    pylab.ylabel('LOSS')\n","    \n","    pylab.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g6eNunkMn1JG","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"egawy42H1v-p","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"6NPSsbdSPjf0","colab_type":"text"},"cell_type":"markdown","source":["### CHECK DATA:"]},{"metadata":{"id":"QkinlRoUt7aL","colab_type":"code","outputId":"5a245670-e2fa-46e0-df3f-e5bc6a1453e1","executionInfo":{"status":"ok","timestamp":1546359549580,"user_tz":-330,"elapsed":3492,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["df_train = pd.read_csv(path + 'df_final_trainset.csv', index_col = 0)\n","df_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movie</th>\n","      <th>user</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>333064</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>911833</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1287538</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>941269</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1694504</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         movie  user  rating\n","333064       0     0       3\n","911833       1     1       5\n","1287538      2     2       3\n","941269       3     3       3\n","1694504      4     4       4"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"aE7HmfcZwM65","colab_type":"code","outputId":"09a80c12-06b2-4e21-fc8e-15018f5a94b8","executionInfo":{"status":"ok","timestamp":1546359549580,"user_tz":-330,"elapsed":2987,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["df_train.movie.max(), df_train.user.max()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4997, 49799)"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"RSOfImaS1sZL","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VGkHYuL81sp6","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"_hzmRHZRozzG","colab_type":"text"},"cell_type":"markdown","source":["# CREATE - TRAIN & TEST PYTORCH DATASET CLASSES:"]},{"metadata":{"colab_type":"code","id":"UgHNOf3ao5wY","colab":{}},"cell_type":"code","source":["class RecommenderData(Dataset):\n","\n","    def __init__(self, path, csv_file_name):\n","        \n","        df = pd.read_csv(path + csv_file_name, index_col = 0)\n","                        \n","        self.len = df.shape[0]\n","        \n","        self.x_data = torch.from_numpy(df.iloc[:, :-1].values).type(torch.LongTensor)\n","        self.y_data = torch.from_numpy(df.iloc[:, -1].values).type(torch.FloatTensor)\n","\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    def __len__(self):\n","        return self.len"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"vVQAPIEso5wz","colab":{}},"cell_type":"code","source":["path = path\n","\n","train_dataset = RecommenderData(path, 'df_final_trainset.csv')\n","test_dataset  = RecommenderData(path, 'df_final_testset.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zmHTeV4HeAOV","colab_type":"code","outputId":"75520a57-b813-45c4-fe43-c8e49a1ebaaa","executionInfo":{"status":"ok","timestamp":1546359558295,"user_tz":-330,"elapsed":2899,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"cell_type":"code","source":["train_dataset.x_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    0,     0],\n","        [    1,     1],\n","        [    2,     2],\n","        ...,\n","        [ 3652,  8903],\n","        [   56, 10623],\n","        [  263, 39396]])"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"9YZiKY2gfhQO","colab_type":"code","outputId":"2e574188-7fad-4306-b86a-f236dc1f4a7f","executionInfo":{"status":"ok","timestamp":1546359561342,"user_tz":-330,"elapsed":1262,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["train_dataset.y_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3., 5., 3.,  ..., 1., 4., 5.])"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"LmD9H9oogvSC","colab_type":"code","outputId":"bbcc2803-4138-4f2a-abca-c13527e72b3a","executionInfo":{"status":"ok","timestamp":1546359561343,"user_tz":-330,"elapsed":821,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["train_dataset.x_data[:, 0].max(), train_dataset.x_data[:, 1].max()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(4997), tensor(49799))"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"uYjXe6eNfl1S","colab_type":"code","outputId":"b6ca0abd-82ab-40d0-a468-a92bc48eef54","executionInfo":{"status":"ok","timestamp":1546359561755,"user_tz":-330,"elapsed":770,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["train_dataset.len, test_dataset.len"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2350408, 587329)"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"5gfV4Wzi1pR3","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"_3mHgy7cqq8Z","colab_type":"text"},"cell_type":"markdown","source":["# MODEL:"]},{"metadata":{"id":"OlgDT-oUdmM8","colab_type":"code","colab":{}},"cell_type":"code","source":["class MatrixFactorization_2(torch.nn.Module):\n","    \n","    def __init__(self, n_users, n_items, embedding_dim, hidden_dim, last_dim):\n","        super().__init__()\n","        \n","\t    # create user & item embeddings of same size:\n","        self.user_embeddings = nn.Embedding(n_users, embedding_dim, sparse=False)\n","        self.item_embeddings = nn.Embedding(n_items, embedding_dim, sparse=False)\n","        \n","        self.weights1 = nn.Linear(embedding_dim, hidden_dim)\n","        self.weights2 = nn.Linear(hidden_dim, last_dim)\n","        \n","        self.batch_norm1 = nn.BatchNorm1d(embedding_dim)\n","        self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n","        \n","        self.dropout1 = nn.Dropout2d(p=0.5)\n","        self.dropout2 = nn.Dropout2d(p=0.25)\n","        \n","        self.relu = nn.ReLU()\n","\n","    def forward(self, user, item):\n","        \n","    \t# CREATING USER LATENT VARIABLES:\n","        # layer 1\n","        user_vec = self.user_embeddings(user)\n","        user_vec = self.batch_norm1(user_vec) \n","        user_vec = self.dropout1(user_vec) \n","        user_vec = self.weights1(user_vec) \n","        user_vec = self.relu(user_vec)\n","        # layers 2 \n","        user_vec = self.batch_norm2(user_vec) \n","        user_vec = self.dropout2(user_vec) \n","        user_vec = self.weights2(user_vec) \n","        user_vec = self.relu(user_vec)\n","        \n","        \n","        # CREATING ITEM LATENT VARIABLES:\n","        # layer 1\n","        item_vec = self.item_embeddings(item)\n","        item_vec = self.batch_norm1(item_vec) \n","        item_vec = self.dropout1(item_vec) \n","        item_vec = self.weights1(item_vec) \n","        item_vec = self.relu(item_vec)\n","        # layers 2 \n","        item_vec = self.batch_norm2(item_vec) \n","        item_vec = self.dropout2(item_vec) \n","        item_vec = self.weights2(item_vec) \n","        item_vec = self.relu(item_vec)\n","        \n","        y_pred = (user_vec * item_vec).sum(1)\n","        \n","        return y_pred   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"c8HOuTu91mlS","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"fu1ITB-SrVYT","colab_type":"text"},"cell_type":"markdown","source":["# MODEL TRAINING & EVALUATION:"]},{"metadata":{"id":"G2GTBQxF2TK3","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 1: Embedding_dim, hidden_dim, last_dim = 100, 50, 5"]},{"metadata":{"id":"FfD84wYYwO20","colab_type":"code","outputId":"b5689cbb-3175-44b6-fb55-6eae5b738a80","executionInfo":{"status":"ok","timestamp":1546339698263,"user_tz":-330,"elapsed":2616341,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":1025}},"cell_type":"code","source":[" n_users, n_items, embedding_dim, hidden_dim, last_dim = 50000, 5000, 100, 50, 5\n","\n","model = MatrixFactorization_2(n_users, n_items, embedding_dim, hidden_dim, last_dim)\n","\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_dataset = train_dataset\n","test_dataset = test_dataset\n","batch_size = 1000\n","n_epochs = 50\n","\n","%time listO_train_losses, listO_test_losses, model = fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>\n","EVALUATING >>\n","Epoch: 001  |  Train Loss: 1.665  | test Loss: 1.091  |\n","Epoch: 002  |  Train Loss: 1.074  | test Loss: 0.972  |\n","Epoch: 003  |  Train Loss: 0.985  | test Loss: 0.925  |\n","Epoch: 004  |  Train Loss: 0.942  | test Loss: 0.903  |\n","Epoch: 005  |  Train Loss: 0.917  | test Loss: 0.891  |\n","Epoch: 006  |  Train Loss: 0.901  | test Loss: 0.882  |\n","Epoch: 007  |  Train Loss: 0.891  | test Loss: 0.879  |\n","Epoch: 008  |  Train Loss: 0.883  | test Loss: 0.875  |\n","Epoch: 009  |  Train Loss: 0.877  | test Loss: 0.870  |\n","Epoch: 010  |  Train Loss: 0.872  | test Loss: 0.870  |\n","Epoch: 011  |  Train Loss: 0.868  | test Loss: 0.868  |\n","Epoch: 012  |  Train Loss: 0.865  | test Loss: 0.871  |\n","Epoch: 013  |  Train Loss: 0.863  | test Loss: 0.867  |\n","Epoch: 014  |  Train Loss: 0.861  | test Loss: 0.867  |\n","Epoch: 015  |  Train Loss: 0.859  | test Loss: 0.865  |\n","Epoch: 016  |  Train Loss: 0.857  | test Loss: 0.866  |\n","Epoch: 017  |  Train Loss: 0.856  | test Loss: 0.866  |\n","Epoch: 018  |  Train Loss: 0.854  | test Loss: 0.866  |\n","Epoch: 019  |  Train Loss: 0.853  | test Loss: 0.864  |\n","Epoch: 020  |  Train Loss: 0.852  | test Loss: 0.867  |\n","Epoch: 021  |  Train Loss: 0.851  | test Loss: 0.866  |\n","Epoch: 022  |  Train Loss: 0.851  | test Loss: 0.864  |\n","Epoch: 023  |  Train Loss: 0.849  | test Loss: 0.864  |\n","Epoch: 024  |  Train Loss: 0.849  | test Loss: 0.863  |\n","Epoch: 025  |  Train Loss: 0.848  | test Loss: 0.863  |\n","Epoch: 026  |  Train Loss: 0.847  | test Loss: 0.863  |\n","Epoch: 027  |  Train Loss: 0.847  | test Loss: 0.864  |\n","Epoch: 028  |  Train Loss: 0.846  | test Loss: 0.864  |\n","Epoch: 029  |  Train Loss: 0.845  | test Loss: 0.863  |\n","Epoch: 030  |  Train Loss: 0.845  | test Loss: 0.864  |\n","Epoch: 031  |  Train Loss: 0.845  | test Loss: 0.865  |\n","Epoch: 032  |  Train Loss: 0.844  | test Loss: 0.864  |\n","Epoch: 033  |  Train Loss: 0.844  | test Loss: 0.864  |\n","Epoch: 034  |  Train Loss: 0.843  | test Loss: 0.864  |\n","Epoch: 035  |  Train Loss: 0.842  | test Loss: 0.863  |\n","Epoch: 036  |  Train Loss: 0.841  | test Loss: 0.862  |\n","Epoch: 037  |  Train Loss: 0.840  | test Loss: 0.862  |\n","Epoch: 038  |  Train Loss: 0.839  | test Loss: 0.861  |\n","Epoch: 039  |  Train Loss: 0.838  | test Loss: 0.862  |\n","Epoch: 040  |  Train Loss: 0.836  | test Loss: 0.862  |\n","Epoch: 041  |  Train Loss: 0.835  | test Loss: 0.858  |\n","Epoch: 042  |  Train Loss: 0.832  | test Loss: 0.857  |\n","Epoch: 043  |  Train Loss: 0.830  | test Loss: 0.854  |\n","Epoch: 044  |  Train Loss: 0.827  | test Loss: 0.853  |\n","Epoch: 045  |  Train Loss: 0.825  | test Loss: 0.852  |\n","Epoch: 046  |  Train Loss: 0.823  | test Loss: 0.849  |\n","Epoch: 047  |  Train Loss: 0.820  | test Loss: 0.846  |\n","Epoch: 048  |  Train Loss: 0.818  | test Loss: 0.844  |\n","Epoch: 049  |  Train Loss: 0.815  | test Loss: 0.841  |\n","Epoch: 050  |  Train Loss: 0.812  | test Loss: 0.839  |\n","\n","RETURNED: listO_train_losses, listO_test_losses, model \n","CPU times: user 29min 7s, sys: 7min 55s, total: 37min 3s\n","Wall time: 43min 35s\n"],"name":"stdout"}]},{"metadata":{"id":"eowMOKfr1g_x","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"64Udb6a12fRb","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 2:  Embedding_dim, hidden_dim, last_dim = 1000, 500, 100"]},{"metadata":{"id":"dvD7AHAfwdD5","colab_type":"code","outputId":"f52d17a4-d8cb-45f7-ca64-a03add6c18c6","executionInfo":{"status":"ok","timestamp":1546355833744,"user_tz":-330,"elapsed":1957247,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":1025}},"cell_type":"code","source":[" n_users, n_items, embedding_dim, hidden_dim, last_dim = 50000, 5000, 1000, 500, 100\n","\n","model = MatrixFactorization_2( n_users, n_items, embedding_dim, hidden_dim, last_dim)\n","\n","learning_rate = 5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_dataset = train_dataset\n","test_dataset = test_dataset\n","batch_size = 1000\n","n_epochs = 50\n","\n","%time listO_train_losses, listO_test_losses, model = fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>\n","EVALUATING >>\n","Epoch: 001  |  Train Loss: 1.046  | test Loss: 0.882  |\n","Epoch: 002  |  Train Loss: 0.888  | test Loss: 0.876  |\n","Epoch: 003  |  Train Loss: 0.867  | test Loss: 0.868  |\n","Epoch: 004  |  Train Loss: 0.860  | test Loss: 0.866  |\n","Epoch: 005  |  Train Loss: 0.855  | test Loss: 0.868  |\n","Epoch: 006  |  Train Loss: 0.853  | test Loss: 0.871  |\n","Epoch: 007  |  Train Loss: 0.840  | test Loss: 0.837  |\n","Epoch: 008  |  Train Loss: 0.808  | test Loss: 0.825  |\n","Epoch: 009  |  Train Loss: 0.793  | test Loss: 0.825  |\n","Epoch: 010  |  Train Loss: 0.786  | test Loss: 0.816  |\n","Epoch: 011  |  Train Loss: 0.782  | test Loss: 0.821  |\n","Epoch: 012  |  Train Loss: 0.779  | test Loss: 0.815  |\n","Epoch: 013  |  Train Loss: 0.777  | test Loss: 0.816  |\n","Epoch: 014  |  Train Loss: 0.775  | test Loss: 0.814  |\n","Epoch: 015  |  Train Loss: 0.774  | test Loss: 0.811  |\n","Epoch: 016  |  Train Loss: 0.772  | test Loss: 0.814  |\n","Epoch: 017  |  Train Loss: 0.771  | test Loss: 0.812  |\n","Epoch: 018  |  Train Loss: 0.770  | test Loss: 0.813  |\n","Epoch: 019  |  Train Loss: 0.769  | test Loss: 0.813  |\n","Epoch: 020  |  Train Loss: 0.769  | test Loss: 0.811  |\n","Epoch: 021  |  Train Loss: 0.768  | test Loss: 0.813  |\n","Epoch: 022  |  Train Loss: 0.768  | test Loss: 0.816  |\n","Epoch: 023  |  Train Loss: 0.767  | test Loss: 0.824  |\n","Epoch: 024  |  Train Loss: 0.766  | test Loss: 0.824  |\n","Epoch: 025  |  Train Loss: 0.766  | test Loss: 0.813  |\n","Epoch: 026  |  Train Loss: 0.766  | test Loss: 0.816  |\n","Epoch: 027  |  Train Loss: 0.766  | test Loss: 0.811  |\n","Epoch: 028  |  Train Loss: 0.765  | test Loss: 0.815  |\n","Epoch: 029  |  Train Loss: 0.764  | test Loss: 0.821  |\n","Epoch: 030  |  Train Loss: 0.764  | test Loss: 0.821  |\n","Epoch: 031  |  Train Loss: 0.764  | test Loss: 0.825  |\n","Epoch: 032  |  Train Loss: 0.764  | test Loss: 0.814  |\n","Epoch: 033  |  Train Loss: 0.763  | test Loss: 0.820  |\n","Epoch: 034  |  Train Loss: 0.764  | test Loss: 0.824  |\n","Epoch: 035  |  Train Loss: 0.763  | test Loss: 0.814  |\n","Epoch: 036  |  Train Loss: 0.771  | test Loss: 0.818  |\n","Epoch: 037  |  Train Loss: 0.761  | test Loss: 0.822  |\n","Epoch: 038  |  Train Loss: 0.761  | test Loss: 0.815  |\n","Epoch: 039  |  Train Loss: 0.762  | test Loss: 0.821  |\n","Epoch: 040  |  Train Loss: 0.762  | test Loss: 0.818  |\n","Epoch: 041  |  Train Loss: 0.761  | test Loss: 0.825  |\n","Epoch: 042  |  Train Loss: 0.762  | test Loss: 0.830  |\n","Epoch: 043  |  Train Loss: 0.761  | test Loss: 0.826  |\n","Epoch: 044  |  Train Loss: 0.761  | test Loss: 0.820  |\n","Epoch: 045  |  Train Loss: 0.761  | test Loss: 0.820  |\n","Epoch: 046  |  Train Loss: 0.761  | test Loss: 0.821  |\n","Epoch: 047  |  Train Loss: 0.761  | test Loss: 0.819  |\n","Epoch: 048  |  Train Loss: 0.761  | test Loss: 0.822  |\n","Epoch: 049  |  Train Loss: 0.760  | test Loss: 0.823  |\n","Epoch: 050  |  Train Loss: 0.760  | test Loss: 0.825  |\n","\n","RETURNED: listO_train_losses, listO_test_losses, model \n","CPU times: user 1h 5min 44s, sys: 30min 10s, total: 1h 35min 54s\n","Wall time: 1h 45min 27s\n"],"name":"stdout"}]},{"metadata":{"id":"jTVs7rlt1Zke","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"PpIOAckD2nmh","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 3: Embedding_dim, hidden_dim, last_dim = 500, 100, 10"]},{"metadata":{"id":"uU2MK81xdmcQ","colab_type":"code","outputId":"ddc7a52b-1948-459a-b61d-25f3592715e1","executionInfo":{"status":"ok","timestamp":1546363390720,"user_tz":-330,"elapsed":3756941,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":1025}},"cell_type":"code","source":[" n_users, n_items, embedding_dim, hidden_dim, last_dim = 50000, 5000, 500, 100, 10\n","\n","model = MatrixFactorization_2( n_users, n_items, embedding_dim, hidden_dim, last_dim)\n","\n","learning_rate = 5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_dataset = train_dataset\n","test_dataset = test_dataset\n","batch_size = 1000\n","n_epochs = 50\n","\n","%time listO_train_losses, listO_test_losses, model = fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>\n","EVALUATING >>\n","Epoch: 001  |  Train Loss: 1.064  | test Loss: 0.887  |\n","Epoch: 002  |  Train Loss: 0.882  | test Loss: 0.869  |\n","Epoch: 003  |  Train Loss: 0.869  | test Loss: 0.870  |\n","Epoch: 004  |  Train Loss: 0.861  | test Loss: 0.871  |\n","Epoch: 005  |  Train Loss: 0.856  | test Loss: 0.865  |\n","Epoch: 006  |  Train Loss: 0.851  | test Loss: 0.860  |\n","Epoch: 007  |  Train Loss: 0.834  | test Loss: 0.836  |\n","Epoch: 008  |  Train Loss: 0.810  | test Loss: 0.821  |\n","Epoch: 009  |  Train Loss: 0.796  | test Loss: 0.818  |\n","Epoch: 010  |  Train Loss: 0.787  | test Loss: 0.820  |\n","Epoch: 011  |  Train Loss: 0.779  | test Loss: 0.824  |\n","Epoch: 012  |  Train Loss: 0.772  | test Loss: 0.807  |\n","Epoch: 013  |  Train Loss: 0.764  | test Loss: 0.807  |\n","Epoch: 014  |  Train Loss: 0.758  | test Loss: 0.800  |\n","Epoch: 015  |  Train Loss: 0.754  | test Loss: 0.804  |\n","Epoch: 016  |  Train Loss: 0.750  | test Loss: 0.799  |\n","Epoch: 017  |  Train Loss: 0.748  | test Loss: 0.800  |\n","Epoch: 018  |  Train Loss: 0.745  | test Loss: 0.801  |\n","Epoch: 019  |  Train Loss: 0.743  | test Loss: 0.805  |\n","Epoch: 020  |  Train Loss: 0.740  | test Loss: 0.802  |\n","Epoch: 021  |  Train Loss: 0.737  | test Loss: 0.803  |\n","Epoch: 022  |  Train Loss: 0.735  | test Loss: 0.805  |\n","Epoch: 023  |  Train Loss: 0.732  | test Loss: 0.800  |\n","Epoch: 024  |  Train Loss: 0.730  | test Loss: 0.805  |\n","Epoch: 025  |  Train Loss: 0.728  | test Loss: 0.800  |\n","Epoch: 026  |  Train Loss: 0.726  | test Loss: 0.800  |\n","Epoch: 027  |  Train Loss: 0.725  | test Loss: 0.801  |\n","Epoch: 028  |  Train Loss: 0.723  | test Loss: 0.800  |\n","Epoch: 029  |  Train Loss: 0.722  | test Loss: 0.797  |\n","Epoch: 030  |  Train Loss: 0.721  | test Loss: 0.802  |\n","Epoch: 031  |  Train Loss: 0.719  | test Loss: 0.810  |\n","Epoch: 032  |  Train Loss: 0.718  | test Loss: 0.800  |\n","Epoch: 033  |  Train Loss: 0.717  | test Loss: 0.800  |\n","Epoch: 034  |  Train Loss: 0.715  | test Loss: 0.798  |\n","Epoch: 035  |  Train Loss: 0.714  | test Loss: 0.801  |\n","Epoch: 036  |  Train Loss: 0.712  | test Loss: 0.801  |\n","Epoch: 037  |  Train Loss: 0.709  | test Loss: 0.797  |\n","Epoch: 038  |  Train Loss: 0.707  | test Loss: 0.805  |\n","Epoch: 039  |  Train Loss: 0.705  | test Loss: 0.814  |\n","Epoch: 040  |  Train Loss: 0.703  | test Loss: 0.801  |\n","Epoch: 041  |  Train Loss: 0.701  | test Loss: 0.803  |\n","Epoch: 042  |  Train Loss: 0.699  | test Loss: 0.799  |\n","Epoch: 043  |  Train Loss: 0.698  | test Loss: 0.800  |\n","Epoch: 044  |  Train Loss: 0.696  | test Loss: 0.801  |\n","Epoch: 045  |  Train Loss: 0.694  | test Loss: 0.799  |\n","Epoch: 046  |  Train Loss: 0.693  | test Loss: 0.807  |\n","Epoch: 047  |  Train Loss: 0.692  | test Loss: 0.802  |\n","Epoch: 048  |  Train Loss: 0.690  | test Loss: 0.800  |\n","Epoch: 049  |  Train Loss: 0.689  | test Loss: 0.810  |\n","Epoch: 050  |  Train Loss: 0.688  | test Loss: 0.804  |\n","\n","RETURNED: listO_train_losses, listO_test_losses, model\n","CPU times: user 39min 48s, sys: 16min 58s, total: 56min 47s\n","Wall time: 1h 2min 35s\n"],"name":"stdout"}]},{"metadata":{"id":"8yOlFHxAxDY2","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"e8TlZIrw2t-h","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 4:  Embedding_dim, hidden_dim, last_dim = 500, 250, 5"]},{"metadata":{"colab_type":"code","id":"rZyQHUrcRUZN","outputId":"ed0e6231-01f0-4dd7-b93f-fa8bbb95b38b","executionInfo":{"status":"ok","timestamp":1546367637861,"user_tz":-330,"elapsed":3805210,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":1025}},"cell_type":"code","source":[" n_users, n_items, embedding_dim, hidden_dim, last_dim = 50000, 5000, 500, 250, 5\n","\n","model = MatrixFactorization_2( n_users, n_items, embedding_dim, hidden_dim, last_dim)\n","\n","learning_rate = 5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_dataset = train_dataset\n","test_dataset = test_dataset\n","batch_size = 1000\n","n_epochs = 50\n","\n","%time listO_train_losses, listO_test_losses, model = fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>\n","EVALUATING >>\n","Epoch: 001  |  Train Loss: 1.065  | test Loss: 0.886  |\n","Epoch: 002  |  Train Loss: 0.882  | test Loss: 0.870  |\n","Epoch: 003  |  Train Loss: 0.868  | test Loss: 0.871  |\n","Epoch: 004  |  Train Loss: 0.861  | test Loss: 0.867  |\n","Epoch: 005  |  Train Loss: 0.857  | test Loss: 0.866  |\n","Epoch: 006  |  Train Loss: 0.846  | test Loss: 0.843  |\n","Epoch: 007  |  Train Loss: 0.816  | test Loss: 0.824  |\n","Epoch: 008  |  Train Loss: 0.799  | test Loss: 0.827  |\n","Epoch: 009  |  Train Loss: 0.789  | test Loss: 0.813  |\n","Epoch: 010  |  Train Loss: 0.782  | test Loss: 0.817  |\n","Epoch: 011  |  Train Loss: 0.773  | test Loss: 0.810  |\n","Epoch: 012  |  Train Loss: 0.765  | test Loss: 0.802  |\n","Epoch: 013  |  Train Loss: 0.759  | test Loss: 0.805  |\n","Epoch: 014  |  Train Loss: 0.755  | test Loss: 0.799  |\n","Epoch: 015  |  Train Loss: 0.751  | test Loss: 0.802  |\n","Epoch: 016  |  Train Loss: 0.748  | test Loss: 0.799  |\n","Epoch: 017  |  Train Loss: 0.745  | test Loss: 0.803  |\n","Epoch: 018  |  Train Loss: 0.743  | test Loss: 0.801  |\n","Epoch: 019  |  Train Loss: 0.740  | test Loss: 0.799  |\n","Epoch: 020  |  Train Loss: 0.737  | test Loss: 0.803  |\n","Epoch: 021  |  Train Loss: 0.734  | test Loss: 0.795  |\n","Epoch: 022  |  Train Loss: 0.732  | test Loss: 0.805  |\n","Epoch: 023  |  Train Loss: 0.730  | test Loss: 0.805  |\n","Epoch: 024  |  Train Loss: 0.727  | test Loss: 0.796  |\n","Epoch: 025  |  Train Loss: 0.726  | test Loss: 0.798  |\n","Epoch: 026  |  Train Loss: 0.724  | test Loss: 0.805  |\n","Epoch: 027  |  Train Loss: 0.722  | test Loss: 0.800  |\n","Epoch: 028  |  Train Loss: 0.721  | test Loss: 0.808  |\n","Epoch: 029  |  Train Loss: 0.720  | test Loss: 0.806  |\n","Epoch: 030  |  Train Loss: 0.719  | test Loss: 0.800  |\n","Epoch: 031  |  Train Loss: 0.718  | test Loss: 0.801  |\n","Epoch: 032  |  Train Loss: 0.717  | test Loss: 0.802  |\n","Epoch: 033  |  Train Loss: 0.716  | test Loss: 0.801  |\n","Epoch: 034  |  Train Loss: 0.715  | test Loss: 0.803  |\n","Epoch: 035  |  Train Loss: 0.714  | test Loss: 0.812  |\n","Epoch: 036  |  Train Loss: 0.713  | test Loss: 0.803  |\n","Epoch: 037  |  Train Loss: 0.712  | test Loss: 0.810  |\n","Epoch: 038  |  Train Loss: 0.711  | test Loss: 0.805  |\n","Epoch: 039  |  Train Loss: 0.710  | test Loss: 0.805  |\n","Epoch: 040  |  Train Loss: 0.708  | test Loss: 0.808  |\n","Epoch: 041  |  Train Loss: 0.707  | test Loss: 0.803  |\n","Epoch: 042  |  Train Loss: 0.706  | test Loss: 0.812  |\n","Epoch: 043  |  Train Loss: 0.705  | test Loss: 0.824  |\n","Epoch: 044  |  Train Loss: 0.703  | test Loss: 0.808  |\n","Epoch: 045  |  Train Loss: 0.702  | test Loss: 0.804  |\n","Epoch: 046  |  Train Loss: 0.701  | test Loss: 0.804  |\n","Epoch: 047  |  Train Loss: 0.699  | test Loss: 0.802  |\n","Epoch: 048  |  Train Loss: 0.698  | test Loss: 0.811  |\n","Epoch: 049  |  Train Loss: 0.697  | test Loss: 0.803  |\n","Epoch: 050  |  Train Loss: 0.696  | test Loss: 0.801  |\n","\n","RETURNED: listO_train_losses, listO_test_losses, model\n","CPU times: user 40min 19s, sys: 17min 12s, total: 57min 31s\n","Wall time: 1h 3min 23s\n"],"name":"stdout"}]},{"metadata":{"id":"p35dSEWmoe8r","colab_type":"text"},"cell_type":"markdown","source":["***"]},{"metadata":{"id":"_TKKRQRSoY1u","colab_type":"text"},"cell_type":"markdown","source":["### TRIAL 5:  Embedding_dim, hidden_dim, last_dim = 500, 250, 15"]},{"metadata":{"id":"tCBJ3C10ttXH","colab_type":"code","outputId":"a01cae34-5126-4030-fb54-dec12c650e41","executionInfo":{"status":"ok","timestamp":1546371999558,"user_tz":-330,"elapsed":3770305,"user":{"displayName":"sajit sasidharan","photoUrl":"https://lh3.googleusercontent.com/-aNa1OPGWWQo/AAAAAAAAAAI/AAAAAAAAK_A/Hhm24WKF_HE/s64/photo.jpg","userId":"02477966862144263705"}},"colab":{"base_uri":"https://localhost:8080/","height":1025}},"cell_type":"code","source":[" n_users, n_items, embedding_dim, hidden_dim, last_dim = 50000, 5000, 500, 250, 15\n","\n","model = MatrixFactorization_2( n_users, n_items, embedding_dim, hidden_dim, last_dim)\n","\n","learning_rate = 5e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","train_dataset = train_dataset\n","test_dataset = test_dataset\n","batch_size = 1000\n","n_epochs = 50\n","\n","%time listO_train_losses, listO_test_losses, model = fn_train_eval(model, train_dataset, test_dataset, batch_size, optimizer, criterion, n_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAINING >>\n","EVALUATING >>\n","Epoch: 001  |  Train Loss: 1.056  | test Loss: 0.880  |\n","Epoch: 002  |  Train Loss: 0.884  | test Loss: 0.876  |\n","Epoch: 003  |  Train Loss: 0.869  | test Loss: 0.875  |\n","Epoch: 004  |  Train Loss: 0.862  | test Loss: 0.867  |\n","Epoch: 005  |  Train Loss: 0.857  | test Loss: 0.867  |\n","Epoch: 006  |  Train Loss: 0.837  | test Loss: 0.841  |\n","Epoch: 007  |  Train Loss: 0.809  | test Loss: 0.819  |\n","Epoch: 008  |  Train Loss: 0.796  | test Loss: 0.820  |\n","Epoch: 009  |  Train Loss: 0.789  | test Loss: 0.815  |\n","Epoch: 010  |  Train Loss: 0.783  | test Loss: 0.813  |\n","Epoch: 011  |  Train Loss: 0.774  | test Loss: 0.806  |\n","Epoch: 012  |  Train Loss: 0.767  | test Loss: 0.805  |\n","Epoch: 013  |  Train Loss: 0.760  | test Loss: 0.810  |\n","Epoch: 014  |  Train Loss: 0.755  | test Loss: 0.799  |\n","Epoch: 015  |  Train Loss: 0.752  | test Loss: 0.800  |\n","Epoch: 016  |  Train Loss: 0.749  | test Loss: 0.801  |\n","Epoch: 017  |  Train Loss: 0.746  | test Loss: 0.802  |\n","Epoch: 018  |  Train Loss: 0.744  | test Loss: 0.812  |\n","Epoch: 019  |  Train Loss: 0.743  | test Loss: 0.804  |\n","Epoch: 020  |  Train Loss: 0.740  | test Loss: 0.809  |\n","Epoch: 021  |  Train Loss: 0.739  | test Loss: 0.808  |\n","Epoch: 022  |  Train Loss: 0.737  | test Loss: 0.804  |\n","Epoch: 023  |  Train Loss: 0.735  | test Loss: 0.798  |\n","Epoch: 024  |  Train Loss: 0.732  | test Loss: 0.804  |\n","Epoch: 025  |  Train Loss: 0.730  | test Loss: 0.810  |\n","Epoch: 026  |  Train Loss: 0.727  | test Loss: 0.802  |\n","Epoch: 027  |  Train Loss: 0.725  | test Loss: 0.797  |\n","Epoch: 028  |  Train Loss: 0.723  | test Loss: 0.804  |\n","Epoch: 029  |  Train Loss: 0.721  | test Loss: 0.799  |\n","Epoch: 030  |  Train Loss: 0.720  | test Loss: 0.802  |\n","Epoch: 031  |  Train Loss: 0.718  | test Loss: 0.799  |\n","Epoch: 032  |  Train Loss: 0.717  | test Loss: 0.801  |\n","Epoch: 033  |  Train Loss: 0.716  | test Loss: 0.803  |\n","Epoch: 034  |  Train Loss: 0.715  | test Loss: 0.805  |\n","Epoch: 035  |  Train Loss: 0.714  | test Loss: 0.810  |\n","Epoch: 036  |  Train Loss: 0.714  | test Loss: 0.803  |\n","Epoch: 037  |  Train Loss: 0.713  | test Loss: 0.799  |\n","Epoch: 038  |  Train Loss: 0.712  | test Loss: 0.800  |\n","Epoch: 039  |  Train Loss: 0.712  | test Loss: 0.801  |\n","Epoch: 040  |  Train Loss: 0.711  | test Loss: 0.799  |\n","Epoch: 041  |  Train Loss: 0.710  | test Loss: 0.808  |\n","Epoch: 042  |  Train Loss: 0.710  | test Loss: 0.799  |\n","Epoch: 043  |  Train Loss: 0.709  | test Loss: 0.794  |\n","Epoch: 044  |  Train Loss: 0.709  | test Loss: 0.799  |\n","Epoch: 045  |  Train Loss: 0.709  | test Loss: 0.805  |\n","Epoch: 046  |  Train Loss: 0.707  | test Loss: 0.806  |\n","Epoch: 047  |  Train Loss: 0.707  | test Loss: 0.806  |\n","Epoch: 048  |  Train Loss: 0.707  | test Loss: 0.806  |\n","Epoch: 049  |  Train Loss: 0.706  | test Loss: 0.804  |\n","Epoch: 050  |  Train Loss: 0.706  | test Loss: 0.799  |\n","\n","RETURNED: listO_train_losses, listO_test_losses, model\n","CPU times: user 40min 4s, sys: 17min 13s, total: 57min 18s\n","Wall time: 1h 2min 49s\n"],"name":"stdout"}]},{"metadata":{"id":"9zaqT-PMttaY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"1QmIQwNEttdo","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"obeZQ4TyID6V","colab_type":"text"},"cell_type":"markdown","source":["## BEST PERFORMANCE : TRIAL 3 - Epoch: 029  |  Train Loss: 0.722  | test Loss: 0.797"]},{"metadata":{"id":"HXbUHgM9tthB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"oeZ6Nne11dth","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"nTM6myeiEhS6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}